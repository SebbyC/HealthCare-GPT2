# Claude Agentic AI Plan for **HealthCareâ€‘GPT**

> **Purpose**Â â€“ Establish a selfâ€‘orchestrating, Claudeâ€‘style agent framework that automates every stage of the HealthCareâ€‘GPT lifecycle: data ingestion, fineâ€‘tuning, evaluation, deployment, and continuous documentation.

---

## 1â€¯Â·â€¯Vision & Scope

| Pillar               | Description                                                                                                                            |
| -------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |
| **Automationâ€‘First** | â€¯Reduce human toil by letting agents run repeatable pipelines (data â†’ model â†’ docs) on a single dev machine or in CI.                  |
| **Domain Alignment** | â€¯Keep the model upâ€‘toâ€‘date with new medical research by continuously ingesting `.csv`, `.md`, `.txt` drops into `HealthCareData/`.     |
| **Transparency**     | â€¯Every agentic action produces artefacts in `docs/changelog/`Â and summaries in `docs/summaries/`, ensuring auditability.               |
| **Resourceâ€‘Aware**   | â€¯Stay within 8â€‘16â€¯GB RAM / consumer GPU constraints; agents manage batchâ€‘sizes, mixedâ€‘precision, and checkpoint pruning automatically. |

---

## 2â€¯Â·â€¯Agent Responsibilities

### 2.1â€¯Data Curator

* WatchÂ `HealthCareData/` for new or changed files.
* Trigger `scripts/preprocess.py` to regenerate `processed/` splits.
* Write a brief extraction report âžœÂ `docs/summaries/{DATE}_data_summary.md`.

### 2.2â€¯TrainerÂ ("LoopMaster")

* Launch fineâ€‘tuning via `scripts/finetune.py`.
* Implements the **Training Loop**:

  1. **Batch Processing** â€“ Pulls token chunks (contextÂ â‰¤â€¯512) in DataLoader.
  2. **Forward Pass** â€“ Runs model â†’ logits.
  3. **Loss Computation** â€“ Crossâ€‘entropy vs. shifted targets.
  4. **Backward Pass** â€“ `loss.backward()` with AMP (fp16) when GPU present.
  5. **Optimizer Step** â€“ `AdamW` update.
  6. **LR Scheduler** â€“ Warmâ€‘upÂ + cosine decay.
  7. **Logging/Eval** â€“ Every *N* steps logs loss, riskâ€‘token accuracy to WeightsÂ &Â Biases; validates onÂ `val_data.txt`.
  8. **Checkpointing** â€“ Saves best & last to `models/finetuned/`.
* Emits training metrics âžœÂ `docs/summaries/{DATE}_train_summary.md`.

### 2.3â€¯Evaluator

* Runs `scripts/evaluate.py` after each epoch or on demand.
* Computes Accuracy, Precision, Recall, F1 on heldâ€‘out CSV.
* If `load_best_model_at_end=True`, reloads best ckpt for final metrics.

### 2.4â€¯Deployer

* Builds/updates Docker image, refreshes `serve.py` container.
* Performs a smoke inference test; if pass, tags Git commit & triggers changelog entry.

### 2.5â€¯Docâ€‘Bot

* Generates/updates:

  * `docs/changelog/{DATE}__{slug}.md` â€“ bullet list of meaningful changes.
  * `docs/summaries/{DATE}_summary.md` â€“ plainâ€‘language overview for stakeholders.
* Keeps this **Claude Plan** synced: inserts new agent roles/steps when pipeline evolves.

---

## 3â€¯Â·â€¯Workflow Orchestration

```mermaid
graph TD
    A[File drop \n in HealthCareData] -->|notify| B(Data Curator)
    B --> C{Preprocessed?}
    C -->|yes| D(Trainer)
    C -->|no| B
    D --> E(Evaluator)
    E --> F{Metrics ok?}
    F -->|yes| G(Deployer)
    F -->|no| H(Adjust hyperparams & retrain)
    G --> I(Docâ€‘Bot)
```

*Agents communicate via JSONÂ RPC over an internal message bus (RabbitMQ or simple cron/CLI for local).*
*Each block can be run manually via make targets: `make curate`, `make train`, `make evaluate`, `make deploy`, `make docs`.*

---

## 4â€¯Â·â€¯File & Naming Conventions

| Directory             | Purpose                       | Naming Rule                            |
| --------------------- | ----------------------------- | -------------------------------------- |
| **docs/plans/**       | Longâ€‘form design docs & RFCs  | `*.md` (snakeâ€‘case)                    |
| **docs/changelog/**   | Machineâ€‘generated change sets | `YYYYMMDD__slug.md`                    |
| **docs/summaries/**   | Daily / run summaries         | `YYYYMMDD_summary.md`                  |
| **models/finetuned/** | Checkpoints                   | `epoch{N}_valLoss{X}.pt` + `latest.pt` |

---

## 5â€¯Â·â€¯Future Extensions

* Switch to distributed training with ðŸ¤—Â Accelerate when >â€¯1â€¯GPU detected.
* Add retrievalâ€‘augmented generation (RAG) for research Q\&A.
* Integrate semantic versioning; have Docâ€‘Bot update `VERSION` file.

---

### Author & Revision

*Initial draft* â€“ generated by ChatGPT **15Â MayÂ 2025**.
Maintainer:Â *AgentÂ Docâ€‘Bot*.
