#!/usr/bin/env python3

import os
import sys
import argparse
import pandas as pd
import json
import re
import random
from datetime import datetime
from pathlib import Path
from sklearn.model_selection import train_test_split

def generate_summary(input_files, output_dir, stats):
    """Generate a summary of the data processing"""
    summary = {
        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "files_processed": input_files,
        "total_records": stats["total_records"],
        "train_records": stats["train_records"],
        "val_records": stats["val_records"],
        "test_records": stats["test_records"],
        "distribution": stats.get("distribution", {})
    }
    
    # Write summary to json for agent communication
    summary_path = Path(output_dir) / f"{datetime.now().strftime('%Y%m%d')}_data_summary.json"
    with open(summary_path, "w") as f:
        json.dump(summary, f, indent=2)
    
    # Also write markdown summary for humans
    md_summary_path = Path("docs/summaries") / f"{datetime.now().strftime('%Y%m%d')}_data_summary.md"
    os.makedirs(os.path.dirname(md_summary_path), exist_ok=True)
    
    with open(md_summary_path, "w") as f:
        f.write(f"# Data Processing Summary {datetime.now().strftime('%Y-%m-%d')}\n\n")
        f.write(f"## Files Processed\n\n")
        for file in input_files:
            f.write(f"- {file}\n")
        f.write(f"\n## Statistics\n\n")
        f.write(f"- Total records: {summary['total_records']}\n")
        f.write(f"- Training set: {summary['train_records']} records ({stats.get('train_percent', 0):.1f}%)\n")
        f.write(f"- Validation set: {summary['val_records']} records ({stats.get('val_percent', 0):.1f}%)\n")
        f.write(f"- Test set: {summary['test_records']} records ({stats.get('test_percent', 0):.1f}%)\n")
        
        if "distribution" in stats and stats["distribution"]:
            f.write(f"\n## Data Distribution\n\n")
            for category, count in stats["distribution"].items():
                percent = (count / summary['total_records']) * 100 if summary['total_records'] > 0 else 0
                f.write(f"- {category}: {count} ({percent:.1f}%)\n")
                
        if "processing_steps" in stats:
            f.write(f"\n## Processing Steps\n\n")
            for i, step in enumerate(stats["processing_steps"], 1):
                f.write(f"{i}. {step}\n")
                
        if "notes" in stats:
            f.write(f"\n## Notes\n\n")
            for note in stats["notes"]:
                f.write(f"- {note}\n")
        
        f.write(f"\n## Generated by\n")
        f.write(f"Agent: Data Curator\n")
        f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    
    print(f"Summary written to {md_summary_path}")

def format_patient_data(row):
    """Convert a patient data row to a text format suitable for training"""
    # Start building patient description
    text = "Patient: "
    
    # Add demographic and health metrics (dynamically based on columns available)
    metrics = []
    for col in row.index:
        if col.lower() != 'highriskflag' and col.lower() != 'patientid' and not pd.isna(row[col]):
            # Format the column name to be more readable
            readable_col = ' '.join(word.capitalize() for word in re.split(r'(?=[A-Z])', col) if word)
            
            # Format the value appropriately
            if isinstance(row[col], bool) or (isinstance(row[col], (int, float)) and (row[col] == 0 or row[col] == 1)):
                # Boolean values
                value = "Yes" if row[col] else "No"
            else:
                # Regular values
                value = str(row[col])
            
            metrics.append(f"{readable_col} {value}")
    
    text += ", ".join(metrics) + "."
    
    # Add risk classification if available
    if 'highriskflag' in [col.lower() for col in row.index]:
        risk_col = next(col for col in row.index if col.lower() == 'highriskflag')
        risk_value = row[risk_col]
        if isinstance(risk_value, (int, float)):
            risk_label = "HighRisk" if risk_value == 1 else "LowRisk"
        else:
            risk_label = "HighRisk" if str(risk_value).lower() in ['true', 'yes', 'high', '1'] else "LowRisk"
        
        text += f" Risk: {risk_label}"
    
    return text

def process_csv(file_path, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, seed=42):
    """Process CSV files into training data"""
    print(f"Processing CSV file: {file_path}")
    df = pd.read_csv(file_path)
    
    # Calculate data distribution if risk flag is present
    distribution = {}
    if 'HighRiskFlag' in df.columns:
        risk_counts = df['HighRiskFlag'].value_counts()
        distribution = {"HighRisk": int(risk_counts.get(1, 0)), 
                       "LowRisk": int(risk_counts.get(0, 0))}
    
    # Convert each row to text format
    formatted_data = [format_patient_data(row) for _, row in df.iterrows()]
    
    # Split data into train, validation, and test sets
    train_data, temp_data = train_test_split(formatted_data, test_size=(val_ratio + test_ratio), random_state=seed)
    
    # Calculate the relative ratio for val from the temp_data
    relative_val_ratio = val_ratio / (val_ratio + test_ratio)
    val_data, test_data = train_test_split(temp_data, test_size=(1-relative_val_ratio), random_state=seed)
    
    # Save to output files
    train_file = Path(output_dir) / "train" / f"{file_path.stem}_train.txt"
    val_file = Path(output_dir) / "val" / f"{file_path.stem}_val.txt"
    test_file = Path(output_dir) / "test" / f"{file_path.stem}_test.txt"
    
    with open(train_file, 'w') as f:
        f.write('\n'.join(train_data))
    
    with open(val_file, 'w') as f:
        f.write('\n'.join(val_data))
    
    with open(test_file, 'w') as f:
        f.write('\n'.join(test_data))
    
    print(f"Saved {len(train_data)} training samples, {len(val_data)} validation samples, and {len(test_data)} test samples")
    
    return {
        "total": len(formatted_data),
        "train": len(train_data),
        "val": len(val_data),
        "test": len(test_data),
        "distribution": distribution
    }

def clean_markdown(content):
    """Clean markdown formatting for better processing"""
    # Remove headers
    content = re.sub(r'#+\s+.*?\n', '\n', content)
    
    # Remove links but keep the text
    content = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', content)
    
    # Remove images
    content = re.sub(r'!\[.*?\]\(.*?\)', '', content)
    
    # Remove code blocks
    content = re.sub(r'```.*?```', '', content, flags=re.DOTALL)
    
    # Remove HTML tags
    content = re.sub(r'<[^>]+>', '', content)
    
    # Remove multiple newlines and replace with single newline
    content = re.sub(r'\n\s*\n+', '\n\n', content)
    
    return content.strip()

def chunk_text(text, max_length=512, overlap=50):
    """Split text into chunks of max_length with some overlap"""
    words = text.split()
    chunks = []
    
    if len(words) <= max_length:
        return [text]
    
    i = 0
    while i < len(words):
        chunk_end = min(i + max_length, len(words))
        chunks.append(' '.join(words[i:chunk_end]))
        i += max_length - overlap
    
    return chunks

def process_text(file_path, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, seed=42):
    """Process text files into training data"""
    print(f"Processing text file: {file_path}")
    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
        content = f.read()
    
    # Clean and chunk the text
    chunks = chunk_text(content)
    
    # Split chunks into train, validation, and test sets
    train_chunks, temp_chunks = train_test_split(chunks, test_size=(val_ratio + test_ratio), random_state=seed)
    
    # Calculate the relative ratio for val from the temp_chunks
    relative_val_ratio = val_ratio / (val_ratio + test_ratio)
    val_chunks, test_chunks = train_test_split(temp_chunks, test_size=(1-relative_val_ratio), random_state=seed)
    
    # Save to output files
    train_file = Path(output_dir) / "train" / f"{file_path.stem}_train.txt"
    val_file = Path(output_dir) / "val" / f"{file_path.stem}_val.txt"
    test_file = Path(output_dir) / "test" / f"{file_path.stem}_test.txt"
    
    with open(train_file, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(train_chunks))
    
    with open(val_file, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(val_chunks))
    
    with open(test_file, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(test_chunks))
    
    print(f"Saved {len(train_chunks)} training chunks, {len(val_chunks)} validation chunks, and {len(test_chunks)} test chunks")
    
    return {
        "total": len(chunks),
        "train": len(train_chunks),
        "val": len(val_chunks),
        "test": len(test_chunks)
    }

def process_markdown(file_path, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, seed=42):
    """Process markdown files into training data"""
    print(f"Processing markdown file: {file_path}")
    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
        content = f.read()
    
    # Clean markdown formatting
    cleaned_content = clean_markdown(content)
    
    # Chunk the content
    chunks = chunk_text(cleaned_content)
    
    # Split chunks into train, validation, and test sets
    train_chunks, temp_chunks = train_test_split(chunks, test_size=(val_ratio + test_ratio), random_state=seed)
    
    # Calculate the relative ratio for val from the temp_chunks
    relative_val_ratio = val_ratio / (val_ratio + test_ratio)
    val_chunks, test_chunks = train_test_split(temp_chunks, test_size=(1-relative_val_ratio), random_state=seed)
    
    # Save to output files
    train_file = Path(output_dir) / "train" / f"{file_path.stem}_train.txt"
    val_file = Path(output_dir) / "val" / f"{file_path.stem}_val.txt"
    test_file = Path(output_dir) / "test" / f"{file_path.stem}_test.txt"
    
    with open(train_file, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(train_chunks))
    
    with open(val_file, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(val_chunks))
    
    with open(test_file, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(test_chunks))
    
    print(f"Saved {len(train_chunks)} training chunks, {len(val_chunks)} validation chunks, and {len(test_chunks)} test chunks")
    
    return {
        "total": len(chunks),
        "train": len(train_chunks),
        "val": len(val_chunks),
        "test": len(test_chunks)
    }

def create_combined_datasets(output_dir):
    """Combine all processed files into single train/val/test files"""
    output_path = Path(output_dir)
    
    # Combine all training files
    train_files = list((output_path / "train").glob("*.txt"))
    val_files = list((output_path / "val").glob("*.txt"))
    test_files = list((output_path / "test").glob("*.txt"))
    
    # Create combined files
    combined_train = output_path / "train_data.txt"
    combined_val = output_path / "val_data.txt"
    combined_test = output_path / "test_data.txt"
    
    # Combine training files
    with open(combined_train, 'w', encoding='utf-8') as out_file:
        for file_path in train_files:
            with open(file_path, 'r', encoding='utf-8', errors='replace') as in_file:
                out_file.write(in_file.read())
                out_file.write("\n\n")
    
    # Combine validation files
    with open(combined_val, 'w', encoding='utf-8') as out_file:
        for file_path in val_files:
            with open(file_path, 'r', encoding='utf-8', errors='replace') as in_file:
                out_file.write(in_file.read())
                out_file.write("\n\n")
    
    # Combine test files
    with open(combined_test, 'w', encoding='utf-8') as out_file:
        for file_path in test_files:
            with open(file_path, 'r', encoding='utf-8', errors='replace') as in_file:
                out_file.write(in_file.read())
                out_file.write("\n\n")
    
    print(f"Created combined datasets: {combined_train}, {combined_val}, {combined_test}")

def preprocess_files(input_dir, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, seed=42):
    """Process all files in input_dir and save to output_dir"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    # Create output directories if they don't exist
    output_path.mkdir(exist_ok=True)
    (output_path / "train").mkdir(exist_ok=True)
    (output_path / "val").mkdir(exist_ok=True)
    (output_path / "test").mkdir(exist_ok=True)
    
    processed_files = []
    stats = {
        "total_records": 0,
        "train_records": 0,
        "val_records": 0,
        "test_records": 0,
        "distribution": {},
        "processing_steps": [
            "Loaded and processed source files",
            "Converted patient data to structured text format",
            "Cleaned and chunked research text",
            "Split data into train, validation, and test sets",
            "Combined data into unified datasets"
        ],
        "notes": []
    }
    
    # Process all files
    for file_path in input_path.glob("**/*"):
        if file_path.is_file():
            print(f"Processing {file_path}...")
            file_stats = {}
            
            try:
                if file_path.suffix.lower() == '.csv':
                    file_stats = process_csv(file_path, output_path, train_ratio, val_ratio, test_ratio, seed)
                elif file_path.suffix.lower() == '.txt':
                    file_stats = process_text(file_path, output_path, train_ratio, val_ratio, test_ratio, seed)
                elif file_path.suffix.lower() == '.md':
                    file_stats = process_markdown(file_path, output_path, train_ratio, val_ratio, test_ratio, seed)
                else:
                    print(f"Skipping unsupported file: {file_path}")
                    continue
                    
                processed_files.append(str(file_path))
                
                # Update statistics
                stats["total_records"] += file_stats["total"]
                stats["train_records"] += file_stats["train"]
                stats["val_records"] += file_stats["val"]
                stats["test_records"] += file_stats["test"]
                
                # Update distribution if available
                if "distribution" in file_stats and file_stats["distribution"]:
                    for category, count in file_stats["distribution"].items():
                        if category in stats["distribution"]:
                            stats["distribution"][category] += count
                        else:
                            stats["distribution"][category] = count
            
            except Exception as e:
                error_msg = f"Error processing {file_path}: {str(e)}"
                print(error_msg)
                stats["notes"].append(error_msg)
    
    # Create combined datasets
    create_combined_datasets(output_path)
    
    # Calculate percentages
    if stats["total_records"] > 0:
        stats["train_percent"] = (stats["train_records"] / stats["total_records"]) * 100
        stats["val_percent"] = (stats["val_records"] / stats["total_records"]) * 100
        stats["test_percent"] = (stats["test_records"] / stats["total_records"]) * 100
    
    # Generate summary
    generate_summary(processed_files, output_dir, stats)
    
    print(f"Preprocessing complete. Processed {len(processed_files)} files with {stats['total_records']} total records.")
    print(f"  - Training: {stats['train_records']} records ({stats.get('train_percent', 0):.1f}%)")
    print(f"  - Validation: {stats['val_records']} records ({stats.get('val_percent', 0):.1f}%)")
    print(f"  - Test: {stats['test_records']} records ({stats.get('test_percent', 0):.1f}%)")

def main():
    parser = argparse.ArgumentParser(description="Preprocess healthcare data for fine-tuning")
    parser.add_argument("--input", default="HealthCareData", help="Input directory containing raw data files")
    parser.add_argument("--output", default="processed", help="Output directory for processed data")
    parser.add_argument("--train-ratio", type=float, default=0.8, help="Ratio of data for training (default: 0.8)")
    parser.add_argument("--val-ratio", type=float, default=0.1, help="Ratio of data for validation (default: 0.1)")
    parser.add_argument("--test-ratio", type=float, default=0.1, help="Ratio of data for testing (default: 0.1)")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducibility (default: 42)")
    
    args = parser.parse_args()
    
    # Validate ratios
    total_ratio = args.train_ratio + args.val_ratio + args.test_ratio
    if not 0.999 <= total_ratio <= 1.001:  # Allow for small floating point errors
        print(f"Error: Train, validation, and test ratios must sum to 1.0, got {total_ratio}")
        sys.exit(1)
    
    preprocess_files(args.input, args.output, args.train_ratio, args.val_ratio, args.test_ratio, args.seed)

if __name__ == "__main__":
    main()